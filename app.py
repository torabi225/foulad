import numpy as np
import streamlit as st
import tensorflow as tf
from PIL import Image, ImageOps
import cv2
import gdown
import os
import traceback

# --- ØªØ¹Ø±ÛŒÙ ØªÙˆØ§Ø¨Ø¹ Ø³ÙØ§Ø±Ø´ÛŒ Ù…Ø¯Ù„ (Ø§Ú¯Ø± Ø¯Ø§Ø±ÛŒØ¯) ---
def my_custom_lambda(x):
    # ØªØ§Ø¨Ø¹ Ù†Ù…ÙˆÙ†Ù‡Ø› ØªØ§Ø¨Ø¹ ÙˆØ§Ù‚Ø¹ÛŒ Ù…Ø¯Ù„ Ø®ÙˆØ¯ Ø±Ø§ Ø§ÛŒÙ†Ø¬Ø§ Ù‚Ø±Ø§Ø± Ø¯Ù‡ÛŒØ¯
    return tf.nn.relu(x)

custom_objects = {
    'my_custom_lambda': my_custom_lambda,
    # Ø§Ú¯Ø± ØªÙˆØ§Ø¨Ø¹ Ø³ÙØ§Ø±Ø´ÛŒ Ø¯ÛŒÚ¯Ø±ÛŒ Ø¯Ø§Ø±ÛŒØ¯ Ø§ÛŒÙ†Ø¬Ø§ Ø§Ø¶Ø§ÙÙ‡ Ú©Ù†ÛŒØ¯
}

# --- Ø¯Ø§Ù†Ù„ÙˆØ¯ Ù…Ø¯Ù„ ---
try:
    file_id = "1aGAUVtVOjBgYyCZ3hcj14U05MYFUYEAq"
    url = f"https://drive.google.com/uc?export=download&id={file_id}"
    model_path = "model.h5"

    if not os.path.exists(model_path):
        st.info("Ø¯Ø± Ø­Ø§Ù„ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ù…Ø¯Ù„ Ø§Ø² Google Drive ...")
        gdown.download(url, model_path, quiet=False)
    else:
        st.success("ÙØ§ÛŒÙ„ Ù…Ø¯Ù„ Ù‚Ø¨Ù„Ø§Ù‹ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø´Ø¯Ù‡ Ø§Ø³Øª.")

    if os.path.exists(model_path):
        size_mb = os.path.getsize(model_path) / (1024 * 1024)
        st.write(f"âœ… Ù…Ø¯Ù„ Ù…ÙˆØ¬ÙˆØ¯ Ø§Ø³Øª â€” Ø§Ù†Ø¯Ø§Ø²Ù‡: {size_mb:.2f} MB")
except Exception as e:
    st.error("âŒ Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø§Ù†Ù„ÙˆØ¯ Ù…Ø¯Ù„:")
    st.text(type(e).__name__ + ": " + str(e))
    st.text(traceback.format_exc())

# --- Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø¯Ù„ ---
model = None
try:
    st.write("âœ… TensorFlow Ù†Ø³Ø®Ù‡:", tf.__version__)
    st.info("Ø¯Ø± Ø­Ø§Ù„ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø¯Ù„...")
    model = tf.keras.models.load_model(model_path, custom_objects=custom_objects, compile=False)
    st.success("Ù…Ø¯Ù„ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ù„ÙˆØ¯ Ø´Ø¯.")
except Exception as e:
    st.error("âŒ Ø®Ø·Ø§ Ø¯Ø± Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø¯Ù„:")
    st.text(type(e).__name__ + ": " + str(e))
    st.text(traceback.format_exc())

# --- ØªØ§Ø¨Ø¹ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ ---
def import_and_predict(image_data, model):
    try:
        size = (200, 200)
        image = ImageOps.fit(image_data, size, method=Image.Resampling.LANCZOS)
        image = image.convert('RGB')
        image_array = np.asarray(image).astype(np.float32) / 255.0
        image_array = np.expand_dims(image_array, axis=0)
        prediction = model.predict(image_array)
        return prediction, image_array, image
    except Exception as e:
        st.error("âŒ Ø®Ø·Ø§ Ø¯Ø± Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ ØªØµÙˆÛŒØ±:")
        st.text(type(e).__name__ + ": " + str(e))
        st.text(traceback.format_exc())
        return None, None, None

# --- Grad-CAM Ø§ØµÙ„Ø§Ø­ Ø´Ø¯Ù‡ ---
def make_gradcam_heatmap(img_array, model, last_conv_layer_name="block5_conv3", pred_index=None):
    try:
        try:
            grad_model = tf.keras.models.Model(
                [model.inputs], [model.get_layer(last_conv_layer_name).output, model.output]
            )
        except Exception as e:
            st.error("âŒ Ø®Ø·Ø§ Ø¯Ø± Ø§ÛŒØ¬Ø§Ø¯ Ù…Ø¯Ù„ Grad-CAM:")
            st.text(type(e).__name__ + ": " + str(e))
            st.text(traceback.format_exc())
            return None

        with tf.GradientTape() as tape:
            try:
                conv_outputs, predictions = grad_model(img_array)
            except Exception as e:
                st.error("âŒ Ø®Ø·Ø§ Ø¯Ø± Ø§Ø¬Ø±Ø§ÛŒ Ù…Ø¯Ù„ Grad-CAM Ø¨Ø±Ø§ÛŒ Ø¯Ø±ÛŒØ§ÙØª Ø®Ø±ÙˆØ¬ÛŒâ€ŒÙ‡Ø§:")
                st.text(type(e).__name__ + ": " + str(e))
                st.text(traceback.format_exc())
                return None

            try:
                if pred_index is None:
                    pred_index = tf.argmax(predictions[0], axis=-1)
                    if isinstance(pred_index, tf.Tensor):
                        pred_index = pred_index.numpy()
                    if isinstance(pred_index, (np.ndarray, list)):
                        pred_index = pred_index.item()
            except Exception as e:
                st.error("âŒ Ø®Ø·Ø§ Ø¯Ø± ØªØ¹ÛŒÛŒÙ† Ø´Ø§Ø®Øµ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ (pred_index):")
                st.text(type(e).__name__ + ": " + str(e))
                st.text(traceback.format_exc())
                return None

            try:
                class_channel = predictions[0][pred_index]
            except Exception as e:
                st.error("âŒ Ø®Ø·Ø§ Ø¯Ø± Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ù„Ø§Ø³ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒâ€ŒØ´Ø¯Ù‡:")
                st.text(type(e).__name__ + ": " + str(e))
                st.text(traceback.format_exc())
                return None

        try:
            grads = tape.gradient(class_channel, conv_outputs)
            pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))
        except Exception as e:
            st.error("âŒ Ø®Ø·Ø§ Ø¯Ø± Ù…Ø­Ø§Ø³Ø¨Ù‡ Ú¯Ø±Ø§Ø¯ÛŒØ§Ù†â€ŒÙ‡Ø§:")
            st.text(type(e).__name__ + ": " + str(e))
            st.text(traceback.format_exc())
            return None

        try:
            conv_outputs = conv_outputs[0]
            heatmap = conv_outputs @ pooled_grads[..., tf.newaxis]
            heatmap = tf.squeeze(heatmap)
        except Exception as e:
            st.error("âŒ Ø®Ø·Ø§ Ø¯Ø± Ø³Ø§Ø®Øª Ù†Ù‚Ø´Ù‡ Ú¯Ø±Ù…Ø§ÛŒÛŒ (heatmap):")
            st.text(type(e).__name__ + ": " + str(e))
            st.text(traceback.format_exc())
            return None

        try:
            heatmap = tf.maximum(heatmap, 0) / tf.reduce_max(heatmap)
            heatmap = heatmap.numpy()
            return heatmap
        except Exception as e:
            st.error("âŒ Ø®Ø·Ø§ Ø¯Ø± Ù†Ø±Ù…Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ Ùˆ ØªØ¨Ø¯ÛŒÙ„ Ù†Ù‚Ø´Ù‡ Ú¯Ø±Ù…Ø§ÛŒÛŒ:")
            st.text(type(e).__name__ + ": " + str(e))
            st.text(traceback.format_exc())
            return None

    except Exception as e:
        st.error("âŒ Ø®Ø·Ø§ÛŒ ØºÛŒØ±Ù…Ù†ØªØ¸Ø±Ù‡ Ø¯Ø± ØªØ§Ø¨Ø¹ make_gradcam_heatmap:")
        st.text(type(e).__name__ + ": " + str(e))
        st.text(traceback.format_exc())
        return None



# --- ØªØ±Ú©ÛŒØ¨ heatmap Ø¨Ø§ ØªØµÙˆÛŒØ± ---
def overlay_heatmap(img, heatmap, alpha=0.4):
    try:
        heatmap = cv2.resize(heatmap, (img.shape[1], img.shape[0]))
        heatmap = np.uint8(255 * heatmap)
        heatmap_color = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)
        overlay = cv2.addWeighted(heatmap_color, alpha, img, 1 - alpha, 0)
        return overlay
    except Exception as e:
        st.error("âŒ Ø®Ø·Ø§ Ø¯Ø± ØªØ±Ú©ÛŒØ¨ heatmap Ø¨Ø§ ØªØµÙˆÛŒØ±:")
        st.text(type(e).__name__ + ": " + str(e))
        st.text(traceback.format_exc())
        return None

# --- CSS ---
st.markdown("""
    <style>
        .title {font-size: 36px; font-weight: bold; text-align: center; color: #1f77b4;}
        .subtitle {font-size: 22px; font-weight: bold; text-align: center; margin-bottom: 30px; color: #333;}
        .section-title {font-size: 20px; font-weight: bold; color: #444; margin-top: 10px;}
        .result {font-size: 22px; font-weight: bold; color: green;}
        .label-text {font-size: 16px; font-weight: bold; color: #000;}
    </style>
""", unsafe_allow_html=True)

# --- Ø¹Ù†ÙˆØ§Ù† ---
st.markdown('<div class="title">ğŸ” Ø³Ø§Ù…Ø§Ù†Ù‡ ØªØ´Ø®ÛŒØµ Ø¹ÛŒÙˆØ¨ Ø³Ø·Ø­ ÙÙˆÙ„Ø§Ø¯</div>', unsafe_allow_html=True)
st.markdown('<div class="subtitle">Ù…Ø¯Ù„ Ù…Ø¨ØªÙ†ÛŒ Ø¨Ø± VGG16 Ø¨Ø§ Ù…Ú©Ø§Ù†ÛŒØ²Ù… ØªÙˆØ¬Ù‡ (Grad-CAM)</div>', unsafe_allow_html=True)

# --- Ø¢Ù¾Ù„ÙˆØ¯ ---
file = st.file_uploader("ğŸ“‚ Ù„Ø·ÙØ§Ù‹ ØªØµÙˆÛŒØ± Ø¹ÛŒØ¨ Ø³Ø·Ø­ ÙÙˆÙ„Ø§Ø¯ Ø±Ø§ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ú©Ù†ÛŒØ¯", type=["jpg", "jpeg", "png"])

if file is not None:
    if model is not None:
        prediction, img_array, resized_image = import_and_predict(Image.open(file), model)

        if prediction is not None:
            try:
                class_labels = ['Crazing', 'Patches', 'Inclusion', 'Pitted_surface', 'Rolled-in_scale', 'Scratches']
                pred_index = np.argmax(prediction)
                pred_label = class_labels[pred_index]
                confidence = prediction[0][pred_index]

                st.markdown(f"<div class='result'>âœ… Ù†ØªÛŒØ¬Ù‡ ØªØ´Ø®ÛŒØµ: {pred_label} ({confidence*100:.2f}%)</div>", unsafe_allow_html=True)

                col1, _, col2, _, col3 = st.columns([1.5, 0.7, 1.5, 0.7, 1.7])

                with col1:
                    st.markdown("<div class='section-title'>ğŸ“· ØªØµÙˆÛŒØ± ÙˆØ±ÙˆØ¯ÛŒ</div>", unsafe_allow_html=True)
                    st.image(resized_image, width=250)

                with col2:
                    st.markdown("<div class='section-title'>ğŸ”¥ Ù†Ù‚Ø´Ù‡ ØªÙˆØ¬Ù‡ (Attention Map)</div>", unsafe_allow_html=True)
                    heatmap = make_gradcam_heatmap(img_array, model)
                    if heatmap is not None:
                        original = np.uint8(255 * img_array[0])
                        attention = overlay_heatmap(original, heatmap)
                        if attention is not None:
                            st.image(attention, width=250)

                with col3:
                    st.markdown("<div class='section-title'>ğŸ“Š Ø§Ø­ØªÙ…Ø§Ù„ Ù‡Ø± Ú©Ù„Ø§Ø³</div>", unsafe_allow_html=True)
                    for i, label in enumerate(class_labels):
                        st.markdown(f"<div class='label-text'>{label}: {prediction[0][i]:.4f}</div>", unsafe_allow_html=True)
                        st.progress(float(prediction[0][i]))
            except Exception as e:
                st.error("âŒ Ø®Ø·Ø§ Ø¯Ø± Ù†Ù…Ø§ÛŒØ´ Ù†ØªØ§ÛŒØ¬:")
                st.text(type(e).__name__ + ": " + str(e))
                st.text(traceback.format_exc())
    else:
        st.error("âŒ Ù…Ø¯Ù„ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù†Ø´Ø¯Ù‡ Ø§Ø³ØªØ› Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ù…Ù…Ú©Ù† Ù†ÛŒØ³Øª.")
else:
    st.info("ğŸ“ Ù„Ø·ÙØ§Ù‹ ÛŒÚ© ØªØµÙˆÛŒØ± Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ú©Ù†ÛŒØ¯.")







